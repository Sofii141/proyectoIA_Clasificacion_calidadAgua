# Predicci√≥n de la Calidad del Agua Dulce con Redes Neuronales

![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)
![Libraries](https://img.shields.io/badge/Librer√≠as-Scikit--learn%20%7C%20Optuna%20%7C%20Pandas-orange.svg)

Este proyecto utiliza una Red Neuronal Artificial (RNA) para resolver un problema de clasificaci√≥n del mundo real: determinar si una muestra de agua dulce es apta para el consumo. El proceso sigue la metodolog√≠a CRISP-DM y aborda desaf√≠os comunes como datos faltantes, variables categ√≥ricas y desbalanceo de clases.

---

## üìö Tabla de Contenidos
1.  [Fase 1: Comprensi√≥n del Negocio y los Datos](#fase-1-comprensi√≥n-del-negocio-y-los-datos)
2.  [Fase 2: An√°lisis Exploratorio de Datos (AED)](#fase-2-an√°lisis-exploratorio-de-datos-aed)
3.  [Fase 3: Preparaci√≥n de los Datos](#fase-3-preparaci√≥n-de-los-datos)
4.  [Fase 4: Construcci√≥n del Modelo](#fase-4-construcci√≥n-del-modelo)
5.  [Fase 5: Evaluaci√≥n y Conclusiones](#fase-5-evaluaci√≥n-y-conclusiones)
6.  [C√≥mo Ejecutar este Proyecto](#c√≥mo-ejecutar-este-proyecto)

---

## Fase 1: Comprensi√≥n del Negocio y los Datos

### 1.1. Comprensi√≥n del Negocio

#### El Problema Global: La Escasez de Agua Potable
El agua dulce es uno de los recursos naturales m√°s vitales y escasos de nuestro planeta. Garantizar el acceso a un suministro de agua seguro es crucial para la salud p√∫blica y la supervivencia de los ecosistemas.

#### El Problema Operativo: Monitoreo Lento y Reactivo
Tradicionalmente, la evaluaci√≥n de la calidad del agua se realiza mediante an√°lisis de laboratorio, un proceso costoso, lento y reactivo. Existe una necesidad cr√≠tica de desarrollar m√©todos m√°s r√°pidos y proactivos para evaluar la potabilidad del agua.

#### Objetivos del Proyecto y Criterios de √âxito
El objetivo principal es desarrollar un **modelo de Machine Learning de alto rendimiento** capaz de predecir si una muestra de agua es "Sostenible" (apta) o "No Sostenible" (no apta).

El √©xito del proyecto se define por la capacidad del modelo para:
1.  **Clasificar correctamente** las muestras con una alta precisi√≥n general.
2.  **Minimizar los Falsos Negativos:** Es de vital importancia identificar correctamente el agua "No Sostenible". Este es nuestro criterio de √©xito principal.

### 1.2. Comprensi√≥n de los Datos

El proyecto utiliza un conjunto de datos p√∫blico de Kaggle, originado en el "Intel OneAPI Online AI Hackathon".

- **Dataset en Kaggle:** [Predict the Quality of Freshwater](https://www.kaggle.com/datasets/naiborhujosua/predict-the-quality-of-freshwater)

El dataset consta de **~5.9 millones de registros** y 22 caracter√≠sticas. Cumple con todos los requisitos del proyecto:
- ‚úÖ **Datos Faltantes:** M√∫ltiples columnas presentan valores nulos.
- ‚úÖ **Variables Categ√≥ricas:** Incluye `Color`, `Source` y `Month`.
- ‚úÖ **Desbalanceo de Clases:** La clase "No Sostenible" es la mayoritaria.

---

## Fase 2: An√°lisis Exploratorio de Datos (AED)

En esta fase, profundizamos en los datos para descubrir patrones y tomar decisiones informadas para el preprocesamiento.

### 2.1. Desbalance de Clases
El an√°lisis de la variable objetivo revela un significativo desbalance: el **70% de las muestras son "No Sostenibles" (Clase 0)**. Esto nos obliga a usar m√©tricas como el F1-Score y el Recall, y a aplicar t√©cnicas de balanceo en el modelado.

![Distribuci√≥n de Clases](images/distribucion_clases.png)

### 2.2. Valores Faltantes
El dataset presenta una cantidad considerable de valores nulos. Sin embargo, ninguna caracter√≠stica supera el 4% de datos faltantes, lo que hace que las t√©cnicas de imputaci√≥n sean una estrategia viable y preferible a la eliminaci√≥n masiva de filas.

![Valores Faltantes por Caracter√≠stica](images/valores_faltantes.png)

### 2.3. Distribuciones y Valores At√≠picos (Outliers)
Los gr√°ficos de viol√≠n revelan que, para contaminantes clave como la **Turbidez** y el **Hierro**, la **Clase 0 (No Sostenible)** presenta valores at√≠picos mucho m√°s extremos. Esto valida que niveles altos de estos par√°metros son indicadores de mala calidad y ser√°n predictores potentes.

![An√°lisis de Outliers](images/analisis_outliers.png)

### 2.4. An√°lisis de Correlaci√≥n
El mapa de calor confirma que las relaciones entre las caracter√≠sticas y la calidad del agua son complejas y **no lineales**, ya que la mayor√≠a de las correlaciones directas son muy bajas. Esto justifica plenamente la elecci√≥n de una Red Neuronal Artificial, un modelo capaz de capturar estos patrones complejos.

![Mapa de Correlaci√≥n](images/mapa_correlacion.png)

---

## Fase 3: Preparaci√≥n de los Datos

El preprocesamiento fue un paso cr√≠tico para preparar los datos para la Red Neuronal. Las principales acciones fueron:
- **Limpieza:** Se eliminaron las columnas irrelevantes como `Index`.
- **Codificaci√≥n:** Las variables categ√≥ricas (`Color`, `Month`, etc.) se convirtieron a formato num√©rico usando `LabelEncoder`.
- **Imputaci√≥n:** Se utiliz√≥ una estrategia de imputaci√≥n robusta (`IterativeImputer`) para rellenar los valores faltantes.
- **Divisi√≥n Estratificada:** Los datos se dividieron en conjuntos de entrenamiento (70%) y prueba (30%) de forma estratificada para mantener la proporci√≥n de clases.
- **Escalado:** Se aplic√≥ `MinMaxScaler` a las caracter√≠sticas num√©ricas para normalizar sus rangos entre 0 y 1, un paso fundamental para el entrenamiento estable de la RNA.

---

## Fase 4: Construcci√≥n del Modelo

### 4.1. Dise√±o de la Arquitectura
La arquitectura de la Red Neuronal (MLP) se dise√±√≥ de forma justificada, con una capa de entrada correspondiente a las caracter√≠sticas, capas ocultas con activaci√≥n **ReLU** para aprender patrones complejos, y una capa de salida con activaci√≥n **Sigmoide** para la clasificaci√≥n binaria. El optimizador elegido fue **Adam**.

### 4.2. Optimizaci√≥n de Hiperpar√°metros con Optuna
Para encontrar la mejor configuraci√≥n de la red (n√∫mero de capas, neuronas, tasa de aprendizaje), se utiliz√≥ **Optuna**, una librer√≠a de optimizaci√≥n autom√°tica. Se ejecutaron m√∫ltiples experimentos para encontrar la arquitectura que **maximizara el F1-Score de la Clase 0 (No Apta)**, alineando la optimizaci√≥n t√©cnica con el objetivo de negocio.

---

## Fase 5: Evaluaci√≥n y Conclusiones

Se entrenaron y evaluaron tres modelos para una comparaci√≥n exhaustiva:
1.  **Modelo 1:** Datos SIN Normalizar (Baseline)
2.  **Modelo 2:** Datos Normalizados
3.  **Modelo 3:** Datos Normalizados + Ponderaci√≥n de Clases

### 5.1. Tabla Comparativa de Resultados

| M√©trica Clave | Modelo 1 (Sin Normalizar) | Modelo 2 (Normalizado) | Modelo 3 (Normalizado + Ponderado) |
| :--- | :---: | :---: | :---: |
| **Recall (Clase 0 - No Apta)** | 0.83 | 0.83 | **0.84** |
| **F1-Score (Clase 0 - No Apta)** | 0.90 | 0.90 | 0.90 |
| **Falsos Negativos (Riesgo)** | 206,530 | 206,272 | **204,553** |
| **Accuracy General** | 87% | 87% | 87% |
| **AUC** | 0.92 | 0.92 | 0.91 |
| **Estabilidad del Entrenamiento**| Inestable | **Estable** | **Estable** |

### 5.2. Conclusi√≥n Final

El an√°lisis comparativo demuestra dos puntos clave:
1.  **La normalizaci√≥n es fundamental:** El modelo entrenado con datos normalizados (Modelo 2) mostr√≥ una convergencia mucho m√°s estable que el modelo sin normalizar.
2.  **La ponderaci√≥n de clases es efectiva:** El Modelo 3 logr√≥ el objetivo de negocio principal al obtener el **Recall m√°s alto para la Clase 0 (0.84)** y, en consecuencia, **el menor n√∫mero de Falsos Negativos (204,553)**.

**Modelo Ganador:** Se selecciona el **Modelo 3 (MLP Normalizado con Ponderaci√≥n de Clases)** como la soluci√≥n final. Aunque su rendimiento general es similar al de los otros, es el modelo m√°s seguro y alineado con nuestro criterio de √©xito principal.

![Matriz de Confusi√≥n del Modelo Ganador](images/matriz_confusion_final.png)

El modelo final es una herramienta robusta y prometedora, con una **precisi√≥n del 87%** y un **AUC de 0.91**, aunque para una implementaci√≥n en el mundo real, se buscar√≠a reducir a√∫n m√°s el 16% de Falsos Negativos restantes.

---

## C√≥mo Ejecutar este Proyecto

1.  **Clonar el Repositorio:**
    ```bash
    git clone https://github.com/tu_usuario/tu_repositorio.git
    cd tu_repositorio
    ```
2.  **Crear y Activar un Entorno Virtual:**
    ```bash
    python -m venv venv
    # En Windows:
    .\venv\Scripts\activate
    # En macOS/Linux:
    source venv/bin/activate
    ```
3.  **Instalar las Dependencias:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Configurar la API de Kaggle:**
    - Descarga tu archivo `kaggle.json` desde tu cuenta de Kaggle.
    - Col√≥calo en la ruta `~/.kaggle/` (macOS/Linux) or `C:\Users\<TuUsuario>\.kaggle\` (Windows).

5.  **Ejecutar Jupyter Notebook:**
    ```bash
    jupyter notebook
    ```
